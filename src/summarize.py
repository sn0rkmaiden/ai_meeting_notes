from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(base_url="http://localhost:1234/v1", api_key="lm-studio")

transcription = """

Спикер 1: Доброе утро, коллеги! Сегодня у нас важная встреча, на которой мы обсудим прогресс по проекту "Новинка". Анна, расскажите, как продвигается маркетинговая кампания.

Спикер 2: Здравствуйте! Мы уже запустили первые рекламные объявления в социальных сетях и получили положительные отклики. Планируем расширить охват на следующей неделе.

Спикер 3: Анна, а как насчет визуальной части? Я подготовил несколько вариантов дизайна, но хотел бы услышать ваше мнение.

Спикер 1: Отлично, Сергей, давайте посмотрим. Покажите нам, что у вас получилось.

Спикер 3: Вот, например, этот вариант с минималистичным стилем или более яркий, с акцентом на цвет. Какой из них лучше подойдет для нашей целевой аудитории?

Спикер 4: Может, стоит провести A/B тестирование? Так мы сможем точно определить, какой дизайн лучше работает.

Спикер 1: Хорошая мысль, Дмитрий. Давайте так и сделаем. Анна, организуйте тестирование на следующей неделе.

Спикер 2: Договорились. Еще у меня есть вопрос по бюджету. Нам нужно дополнительное финансирование для запуска рекламы в новых каналах.

Спикер 1: Бюджет пока ограничен. Давайте сначала посмотрим результаты текущего этапа, а потом обсудим возможность увеличения.

Спикер 4: Согласен, сначала нужно оценить эффективность текущих вложений.

Спикер 1: Хорошо, коллеги. На этом наша встреча завершена. Продолжаем работу над проектом и держим друг друга в курсе. Спасибо за участие!

"""

summarization_prompt = """Ты - виртуальный помощник. Подведи итоги встречи, опиши, к чему пришли участники собрания.\
        Резюме должно быть кратким и понятным, но при этом точным и отражать основное сообщение.\
        Кроме того, резюме должно избегать любых личных предубеждений или интерпретаций\
        и оставаться объективным и фактическим. Напиши ответ на русском языке."""

messages = [
    (
        "system",
        transcription,
    ),
    ("human", transcription),
]
ai_msg = llm.invoke(messages)
print(ai_msg.content)

